# (PART) Inference {-} 

# Sampling {#sampling}

```{r setup_infer, include=FALSE, purl=FALSE}
chap <- 8
lc <- 0
rq <- 0
# **`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`**
# **`r paste0("(RQ", chap, ".", (rq <- rq + 1), ")")`**

knitr::opts_chunk$set(
  tidy = FALSE, 
  out.width = '\\textwidth', 
  fig.height = 4,
  warning = FALSE
  )

# This bit of code is a bug fix on asis blocks, which we use to show/not show LC
# solutions, which are written like markdown text. In theory, it shouldn't be
# necessary for knitr versions <=1.11.6, but I've found I still need to for
# everything to knit properly in asis blocks. More info here: 
# https://stackoverflow.com/questions/32944715/conditionally-display-block-of-markdown-text-using-knitr
library(knitr)
knit_engines$set(asis = function(options) {
  if (options$echo && options$eval) knit_child(text = options$code)
})

# This controls which LC solutions to show. Options for solutions_shown: "ALL"
# (to show all solutions), or subsets of c('5-1', '5-2','5-3', '5-4'), including
# the null vector c('') to show no solutions.
solutions_shown <- c('')
show_solutions <- function(section){
  return(solutions_shown == "ALL" | section %in% solutions_shown)
  }
```


In this chapter we kick off the third and final segment of this book, statistical inference, by learning about **sampling**. The concepts behind sampling form the basis of confidence intervals and hypothesis testing, which we'll cover in Chapters \@ref(ci) and \@ref(hypo) respectively. We will see that the tools that you learned in the data science segment of this book (data visualization, "tidy" data format, and data wrangling) will also play an important role here in the development of your understanding.  As mentioned before, the concepts throughout this text all build into a culmination allowing you to "think with data."

### Needed packages {-}

Let's load all the packages needed for this chapter (this assumes you've already installed them). If needed, read Section \@ref(packages) for information on how to install and load R packages.

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(moderndive)
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Packages needed internally, but not in text.
library(knitr)
```

## Terminology

Before we can start studying sampling, we need to define some terminology.


1. **Population**: The population is the (usually) large pool of observational units that we are interested in.
1. **Population parameter**: A population parameter is a numerical quantify of interest about a population, such as a proportion or a mean. 
1. **Census**: An enumeration of every member of a population. Ex: the Decennial United States census.
1. **Sample**: A sample is a smaller collection of observational units that is selected from the population. We would like to *infer* about the population based on this sample.
1. **Sampling**: Sampling refers to the process of selecting observations from a population.  There are both random and non-random ways this can be done.
1. **Representative sampling**: A sample is said be a representative sample if the characteristics of observational units selected are a good approximation of the characteristics from the original population.
1. **Generalizability**: Generalizability refers to the largest group in which it makes sense to make inferences about from the sample collected.  This is directly related to how the sample was selected.
1. **Bias**: Bias corresponds to a favoring of one group in a population over another group. Or put differently, when certain members of a population have a higher chance of being included in a sample than others.
1. **Statistic**: A statistic is a calculation based on one or more variables measured in the sample. 
1. **Point estimates/sample statistics**: These are statistics, computed based on a sample, that estimate an unknow population parameter. 


## "In real life" sampling

Consider the following "sampling bowl" consisting of 2400 balls, which are either red, white, or green. We are interested in knowing the proportion of balls in the sampling bowl that are red, but are too lazy to count the number of balls out of 2400 that are red. In other words, we're not interested in conducting a census. So instead we attempt to estimate the proportion red by using the sampling "shovel" to extract a sample of size $n$ = 50 balls, and count the proportion of these that are red. However, before we extracted a sample using this shovel, we made sure to give the balls a good stir, ensuring we have random sampling.

```{r tub1, echo=FALSE, fig.cap="Sampling from a sampling bowl", purl=FALSE}
knitr::include_graphics("images/sampling_bowl.jpeg")
```

We put students to the task of estimating the proprotion of balls in the tub that are red, because frankly, we're too lazy to do so ourselves! Groups of students "in real life" took random samples of size $n$ = 50. Thank you Niko, Sophie, Caitlin, Yaw, and Drew for doing double duty! In other, we have 10 samples of size $n$ = 50:

```{r, eval=FALSE}
bowl_samples
```
```{r students, echo=FALSE}
bowl_samples %>% 
  knitr::kable(
    digits = 3,
    caption = "In real life: 10 samples of size 50",
    booktabs = TRUE
  )
```

For each sample of size $n$ = 50, what is the sample proportion red? In other words, what are the point estimates $\widehat{p}$ based on a sample of size $n$ = 50 of $p$, the true proportion of balls in the tub that is red? We can easily compute this using the `mutate()` function from the `dplyr` package we studied extensively in Chapter \@ref(wrangling):

```{r, eval=FALSE}
bowl_samples <- bowl_samples %>% 
  mutate(prop_red = red/n) %>% 
  select(group, prop_red)
bowl_samples
```
```{r sample-prop-red, echo=FALSE}
bowl_samples <- bowl_samples %>% 
  mutate(prop_red = red/n) %>% 
  select(group, prop_red)
bowl_samples %>%
  knitr::kable(
    digits = 3,
    caption = "In real life: 10 sample proportions red based on samples of size 50",
    booktabs = TRUE
  )
```

We see that one group got a sample proportion $\widehat{p}$ as low as 28% while another got a sample proportion $\widehat{p}$ as high as 0.44. Why are these different? Why is there this variation? Because of *sampling variability*! Sampling is inherently random, so for a sample of $n$ = 50 balls, we'll never get exactly the same number of red balls.

Let's visualize this using our data visualization skills that you honed in Chapter \@ref(viz)! Let's investigate the distribution of these 10 sample proportion red $\widehat{p}$ each based on a random sample of size $n$ = 50 using a histogram, an appropriate visualization since `prop_red` is numerical:

```{r samplingdistribution, echo=FALSE, fig.cap="In real life: 10 sample proportions red based on 10 samples of size 50"}
ggplot(bowl_samples, aes(x = prop_red)) +
  geom_histogram(binwidth = 0.05) +
  labs(x="Sample proportion red in sample of size n=50", y="Number of samples",
       title="Sample proportion red in ten samples of size n=50") 
```

Let's as ourselves some questions:

1. Where is the histogram centered?
1. What is the spread of this histogram?

Recall from Section \@ref(summarize) the mean and the standard deviation are two summary statistics that would answer this question:

```{r, eval=FALSE}
bowl_samples %>% 
  summarize(mean = mean(prop_red), sd = sd(prop_red))
```
```{r, echo=FALSE}
bowl_summaries <- bowl_samples %>% 
  summarize(mean = mean(prop_red), sd = sd(prop_red))
bowl_summaries %>% 
  kable(digits = 3)
```

What you have just unpacked are some very deep and very subtle concepts in statistical inference:

1. The histogram in Figure \@ref(fig:samplingdistribution) is called the **sampling distribution** of $\widehat{p}$ based on samples of size $n=50$. It describes how values of the sample proportion red will vary from sample-to-sample due to the aforementioned **sampling variability**.
1. If the sampling is done in an unbiased and random fashion, in other words we made sure to stir the bowl before we sampled, then the sampling distribution will be guaranteed to be centered at the true unknown population proportion red, or in other words the true number of balls out of 2400 that are red. In this case, these 10 values of $\widehat{p}$ are centered at `r bowl_summaries %>% pull(mean)`
1. The spread of this histogram, as quantified by the standard devation of `r bowl_summaries %>% pull(sd)`, is called the **standard error**. It quantifies the variability of our estimates $\widehat{p}$.



## Virtual sampling

In the `moderndive` package, we've included a data frame called `bowl` that actually is a virtual version of the above sampling bowl in Figure \@ref(fig:tub1) with all `r nrow(bowl)` balls! While we present a snap shot of the first 10 rows of `bowl` below, you should `View()` it in RStudio to convince yourselves that `bowl` is indeed a virtual version of the image above. 

```{r, eval=FALSE}
View(bowl)
```
```{r, echo=FALSE}
bowl %>% 
  slice(1:10) %>%
  knitr::kable(
    align = c("r", "r"),
    digits = 3,
    caption = "First 10 balls in virtual sampling bowl",
    booktabs = TRUE
  )
```

Note that the balls are not actually marked with numbers; the variable `ball_ID` are merely used as an identification variable for each row of `bowl` (recall our previous discussion on identification variables in Subsection \@ref(identification-vs-measurement) in "Data Tidying" Chapter \@ref(tidy).

Let's replicate what the groups of students did above but *virtually*. We are going to now simulate using a computer what our students did by hand in Table \@ref(tab:students) using the `rep_sample_n()` function which the `moderndive` package borrows from the `infer` package we'll see shortly. The `rep_sample_n()` function takes the following arguments:

* `tbl`: a data frame representing the population you wish to infer about. We'll set this to `bowl`, since this is the (virtual) population of interest.
* `size`: the sample size $n$ in question. We'll set this to 50, micking the number of slots in the sampling "shovel" in the image in Figure \@ref(fig:tub1).
* `replace`: A logical `TRUE/FALSE` value indicating whether or not to put each ball back into the bowl after we've sampled it. In our case, we'll set this to `FALSE` since we are sampling 50 balls at once, not 50 single balls individually.
* `reps`: the number of samples of size $n$ = `size` to extract. We'll set this to 10, mimicking the data we have in Table \@ref(tab:students).

Let's apply this function to mimick our situation above and `View()` the data. The output is rather large, so we won't display it below.

```{r, echo=FALSE}
set.seed(76)
```
```{r, eval=FALSE}
all_samples <- rep_sample_n(bowl, size = 50, reps = 10)
View(all_samples)
```
```{r, echo=FALSE}
all_samples <- rep_sample_n(bowl, size = 50, reps = 10)
```

Scroll through the spreadsheet viewer, you'll notice

1. The values of `replicate` (`1` through `10`) come in bunches of 50, representing the 10 groups respective samples of size $n$ = 50.
1. The `ball_ID` identification variable is all over the place, suggesting we really are (virtual) randomly sampling balls.
1. `color` represents the color of each of the virtually sampled balls.

What is the proportion red for each group as denoted by the `replicate` variable? Again, let's leverage your data ninja skills from Chapter \@ref(wrangling).

```{r, eval=FALSE}
bowl_samples_virtual <- all_samples %>% 
  mutate(is_red = color == "red") %>% 
  group_by(replicate) %>% 
  summarize(prop_red = mean(is_red))
bowl_samples_virtual
```
```{r sample-prop-red-virtual, echo=FALSE}
bowl_samples_virtual <- all_samples %>% 
  mutate(is_red = color == "red") %>% 
  group_by(replicate) %>% 
  summarize(prop_red = mean(is_red))
bowl_samples_virtual %>%
  knitr::kable(
    digits = 3,
    caption = "Virtual simulation: 10 sample proportions red based on samples of size 50",
    booktabs = TRUE
  )
```

Compare Tables \@ref(tab:sample-prop-red) and Table \@ref(tab:sample-prop-red-virtual); they are similar in output format and also the resulting `prop_red` are similar in values. Let's plot this using the same histogram code as in Figure \@ref(fig:samplingdistribution), but switching out `bowl_samples` for `bowl_samples_virtual`:

```{r sampling-distribution-virtual, echo=FALSE, fig.cap="Virtual simulation: 10 sample proportions red based on 10 samples of size 50"}
ggplot(bowl_samples_virtual, aes(x = prop_red)) +
  geom_histogram(binwidth = 0.05) +
  labs(x="Sample proportion red in sample of size n=50", y="Number of samples",
       title="Sample proportion red in ten samples of size n=50") 
```

We've replicated the sampling distribution, but using simulated random samples, instead of the "in real life" random samples that our students collected in Table \@ref(tab:students). Let's compute the center of this histogram and it's standard deviation, which recall has a specific name: the standard error.

```{r, eval=FALSE}
bowl_samples_virtual %>% 
  summarize(mean = mean(prop_red), sd = sd(prop_red))
```
```{r, echo=FALSE}
bowl_summaries_virtual <- bowl_samples %>% 
  summarize(mean = mean(prop_red), sd = sd(prop_red))
bowl_summaries %>% 
  kable(digits = 3)
```



## Intense virtual sampling 

Say we were feeling particularly unkind to Yaw and Drew and made them draw not 10 samples of size $n$ = 50, but TEN THOUSAND such samples. They would probably be at work for days! This is where computer simulations come really in handy: doing repetive and boring tasks quickly. To achieve this virtually, we just use same code as above but setting `reps = 10000`:

```{r, echo=FALSE}
set.seed(76)
```
```{r sampling-distribution-virtual-2, echo=TRUE, fig.cap="Virtual simulation: Ten thousand sample proportions red based on ten thousand samples of size 50"}
# Draw one million samples of size n = 50
all_samples <- rep_sample_n(bowl, size = 50, reps = 10000)

# For each sample, as marked by the variable `replicate`, compute the proportion red
bowl_samples_virtual <- all_samples %>% 
  mutate(is_red = color == "red") %>% 
  group_by(replicate) %>% 
  summarize(prop_red = mean(is_red))

# Plot the histogram
ggplot(bowl_samples_virtual, aes(x = prop_red)) +
  geom_histogram(binwidth = 0.02) +
  labs(x="Sample proportion red in sample of size n=50", y="Number of samples",
       title="Sample proportion red in ten samples of size n=50") 
```

This distribution looks an awful lot like the normal distribution. That's because is is the normal distribution! Let's compute the center of this sampling distribution and the standard error again:

```{r, eval=FALSE}
bowl_samples_virtual %>% 
  summarize(mean = mean(prop_red), sd = sd(prop_red))
```
```{r, echo=FALSE}
bowl_summaries_virtual <- bowl_samples %>% 
  summarize(mean = mean(prop_red), sd = sd(prop_red))
bowl_summaries %>% 
  kable(digits = 3)
```


```{block, type='learncheck', purl=FALSE}
**_Learning check_**
```

**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** Repeat the above "extreme" virtual sampling exercise for 10,000 samples of size $n$ = 100. What do you notice is different about the histogram, i.e. the sampling distribution. 

**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** Repeat the above "extreme" virtual sampling exercise for 10,000 samples of size $n$ = 25. What do you notice is different about the histogram, i.e. the sampling distribution, when compared to the instances when the samples were of size $n$ = 50 and $n$ = 100. 

**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** Repeat the above "extreme" virtual sampling exercise for 10,000 samples of size $n$ = 50, but where the population is the `pennies` dataset in the `moderndive` package representing `r nrow(pennies)` pennies and where the population parameter of interest is the average year of minting of the `r nrow(pennies)` pennies.  See the help file `?pennies` for more information about this dataset. 

```{block, type='learncheck', purl=FALSE}
```



## Central Limit Theorem

What you have just shown in the previous is a very famous theorem, or mathematically proven truth, called the *Central Limit Theorem* which loosely states that when samples means and sample proportions are based on larger and larger samples, the sampling distribution corresponding to these point estimates get

1. More and more normal
1. More and more narrow

Shuyi Chiou, Casey Dunn, and Pathikrit Bhattacharyya created the following 3m38s video explaining this crucial theorem to statistics using as examples, what else?

1. The average weight of wild bunny rabbits!
1. The average wing span of dragons!

<center>
<iframe width="800" height="450" src="https://www.youtube.com/embed/jvoxEYmQHNM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</center>




## Conclusion

### What's to come?

This chapter serves as an introduction to theoretical underpinning of the statistical inference techniques that will be discussed in greater detail in Chapter \@ref(ci) for confidence intervals and Chapter \@ref(hypo) for hypothesis testing. 

### Script of R code

An R script file of all R code used in this chapter is available [here](https://moderndive.netlify.com/scripts/08-sampling.R).

