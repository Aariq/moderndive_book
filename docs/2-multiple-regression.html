<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>An Introduction to Statistical and Data Sciences via R</title>
  <meta name="description" content="An open-source and fully-reproducible electronic textbook bridging the gap between traditional introductory statistics and data science courses.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="An Introduction to Statistical and Data Sciences via R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://moderndive.com/" />
  <meta property="og:image" content="http://moderndive.com/images/logos/book_cover.png" />
  <meta property="og:description" content="An open-source and fully-reproducible electronic textbook bridging the gap between traditional introductory statistics and data science courses." />
  <meta name="github-repo" content="moderndive/moderndive_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="An Introduction to Statistical and Data Sciences via R" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic textbook bridging the gap between traditional introductory statistics and data science courses." />
  <meta name="twitter:image" content="http://moderndive.com/images/logos/book_cover.png" />

<meta name="author" content="Chester Ismay and Albert Y. Kim">


<meta name="date" content="2018-01-31">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="images/logos/favicons/apple-touch-icon.png">
  <link rel="shortcut icon" href="images/logos/favicons/favicon.ico" type="image/x-icon">
<link rel="prev" href="index.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89938436-1', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#sec:intro-for-students"><i class="fa fa-check"></i><b>1.1</b> Introduction for students</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#subsec:learning-goals"><i class="fa fa-check"></i><b>1.1.1</b> What you will learn from this book</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#subsec:pipeline"><i class="fa fa-check"></i><b>1.1.2</b> Data/science pipeline</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#subsec:reproducible"><i class="fa fa-check"></i><b>1.1.3</b> Reproducible research</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#final-note-for-students"><i class="fa fa-check"></i><b>1.1.4</b> Final note for students</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#sec:intro-instructors"><i class="fa fa-check"></i><b>1.2</b> Introduction for instructors</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#who-is-this-book-for"><i class="fa fa-check"></i><b>1.2.1</b> Who is this book for?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#sec:connect-contribute"><i class="fa fa-check"></i><b>1.3</b> Connect and contribute</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#sec:about-book"><i class="fa fa-check"></i><b>1.4</b> About this book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html"><i class="fa fa-check"></i><b>2</b> Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="2.1" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model3"><i class="fa fa-check"></i><b>2.1</b> Two numerical explanatory variables</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>2.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>2.1.2</b> Multiple regression</a></li>
<li class="chapter" data-level="2.1.3" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>2.1.3</b> Observed/fitted values and residuals</a></li>
<li class="chapter" data-level="2.1.4" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model3residuals"><i class="fa fa-check"></i><b>2.1.4</b> Residual analysis</a></li>
<li class="chapter" data-level="2.1.5" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#your-turn"><i class="fa fa-check"></i><b>2.1.5</b> Your turn</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model4"><i class="fa fa-check"></i><b>2.2</b> One numerical &amp; one categorical explanatory variable</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>2.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>2.2.2</b> Multiple regression</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>2.2.3</b> Mutiple regression with interaction effects</a></li>
<li class="chapter" data-level="2.2.4" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>2.2.4</b> Observed/fitted values and residuals</a></li>
<li class="chapter" data-level="2.2.5" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#model4residuals"><i class="fa fa-check"></i><b>2.2.5</b> Residual analysis</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#related-topics"><i class="fa fa-check"></i><b>2.3</b> Related topics</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#correlationcoefficient2"><i class="fa fa-check"></i><b>2.3.1</b> More on the correlation coefficient</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#simpsonsparadox"><i class="fa fa-check"></i><b>2.3.2</b> Simpson’s Paradox</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-multiple-regression.html"><a href="2-multiple-regression.html#script-of-r-code"><i class="fa fa-check"></i><b>2.3.3</b> Script of R code</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical and Data Sciences via R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<html>
<img src='http://moderndive.com/images/logos/wide_format.png' alt="ModernDive">
</html>
<div id="multiple-regression" class="section level1">
<h1><span class="header-section-number">2</span> Multiple Regression</h1>
<p>In Chapter <a href="#regression"><strong>??</strong></a> we introduced ideas related to modeling, in particular that the fundamental premise of modeling is <em>to make explicit the relationship</em> between an outcome variable <span class="math inline">\(y\)</span>, also called a dependent variable and an explanatory/predictor variable <span class="math inline">\(x\)</span>, also called an independent variable or covariate. There are many modeling approaches one could take, among the most well-known being linear regression which was the focus of the last chapter. Whereas in the last chapter we only focused on regression scenarios where there is only one explanatory/predictor variable, in this chapter, we now focus on modeling scenarios where there is more than one; this is known as multiple regression. You can imagine when trying to model a particular outcome variable, like teaching evaluation score as in Section <a href="#model1"><strong>??</strong></a> or life expectancy as in Section <a href="#model2"><strong>??</strong></a>, it would be very useful to incorporate more than one explanatory variable.</p>
<p>Since our regression models will now consider more than one explanatory/predictor variable, the interpretation of the associated effect of any one explanatory/predictor variables must be made in conjunction with the others. For example, say we are modeling individuals’ incomes as a function of their number of years of education and their parents wealth, when interpreting the effect of education on income, one has to consider the effect of their parents’s wealth at the same time, as these two variables are almost certainly related.</p>
<div id="needed-packages" class="section level3 unnumbered">
<h3>Needed packages</h3>
<p>Let’s load all the packages needed for this chapter (this assumes you’ve already installed them). Read Section <a href="#packages"><strong>??</strong></a> for information on how to install and load R packages.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(moderndive)
<span class="kw">library</span>(ISLR)</code></pre></div>
</div>
<div id="model3" class="section level2">
<h2><span class="header-section-number">2.1</span> Two numerical explanatory variables</h2>
<p>Let’s now attempt to identify factors that are associated with how much credit card debt an individual will have. The textbook <a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning with Applications in R</a> by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani is an intermediate-level textbook on statistical and machine learning freely available <a href="http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf">here</a>. It has an accompanying R packaged called <code>ISLR</code> with datasets that the authors use to demonstrate various machine learning methods. One dataset that is frequently used by the authors is the <code>Credit</code> dataset where predictions are made on the credit card balance held by <span class="math inline">\(n\)</span> = 400 credit card holders based on information about them like income, credit limit, and education level.</p>
<p>Since no information was provided as to who these <span class="math inline">\(n\)</span> = 400 individuals are and how they came to be included in this dataset, it will be hard to make any scientific claims based on this data. That being said, we’ll still use <code>Credit</code> to demonstrate multiple regression with:</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>, in this case teaching credit card balance.</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>A first numerical explanatory variable <span class="math inline">\(x_1\)</span>. In this case, their credit limit.</li>
<li>A second numerical explanatory variable <span class="math inline">\(x_2\)</span>. In this case, their income (in thousands of dollars).</li>
</ol></li>
</ol>
<div id="model3EDA" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Exploratory data analysis</h3>
<p>Let’s load the <code>Credit</code> data and <code>select()</code> only the needed subset of the variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
Credit &lt;-<span class="st"> </span>Credit <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Balance, Limit, Income)</code></pre></div>
<p>Let’s look at the raw data values both by bringing up RStudio’s spreadsheet viewer and the <code>glimpse()</code> function, although in Table <a href="2-multiple-regression.html#tab:model3-data-preview">2.1</a> we only show 5 randomly selected credit card holders out of 400:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(Credit)</code></pre></div>
<table>
<caption><span id="tab:model3-data-preview">Table 2.1: </span>Random sample of 5 credit card holders</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Balance</th>
<th align="right">Limit</th>
<th align="right">Income</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>237</td>
<td align="right">489</td>
<td align="right">4986</td>
<td align="right">42.5</td>
</tr>
<tr class="even">
<td>375</td>
<td align="right">588</td>
<td align="right">4840</td>
<td align="right">29.4</td>
</tr>
<tr class="odd">
<td>221</td>
<td align="right">1246</td>
<td align="right">5765</td>
<td align="right">44.8</td>
</tr>
<tr class="even">
<td>361</td>
<td align="right">712</td>
<td align="right">5891</td>
<td align="right">53.6</td>
</tr>
<tr class="odd">
<td>117</td>
<td align="right">0</td>
<td align="right">2117</td>
<td align="right">35.2</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(Credit)</code></pre></div>
<pre><code>Observations: 400
Variables: 3
$ Balance &lt;int&gt; 333, 903, 580, 964, 331, 1151, 203, 872, 279, 1350, 1407, 0...
$ Limit   &lt;int&gt; 3606, 6645, 7075, 9504, 4897, 8047, 3388, 7114, 3300, 6819,...
$ Income  &lt;dbl&gt; 14.9, 106.0, 104.6, 148.9, 55.9, 80.2, 21.0, 71.4, 15.1, 71...</code></pre>
<p>Let’s look at some summary statistics:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(Credit)</code></pre></div>
<pre><code>    Balance         Limit           Income     
 Min.   :   0   Min.   :  855   Min.   : 10.4  
 1st Qu.:  69   1st Qu.: 3088   1st Qu.: 21.0  
 Median : 460   Median : 4622   Median : 33.1  
 Mean   : 520   Mean   : 4736   Mean   : 45.2  
 3rd Qu.: 863   3rd Qu.: 5873   3rd Qu.: 57.5  
 Max.   :1999   Max.   :13913   Max.   :186.6  </code></pre>
<p>We observe for example</p>
<ol style="list-style-type: decimal">
<li>The mean and median credit card balance is around $500. 25% of card holders had debts of 69 dollars or less.</li>
<li>The mean and median credit card limit is just under $5000.</li>
<li>75% of these card holders had incomes of $57,500 or less.</li>
</ol>
<p>Since our outcome variable <code>Balance</code> and the explanatory variables <code>Limit</code> and <code>Rating</code> are numerical, we can compute the correlation coefficient between pairs of these variables. There are two way of doing this. First, we could run the <code>cor()</code> command as seen in Section <a href="#model1EDA"><strong>??</strong></a> twice, once for each explanatory variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(Credit<span class="op">$</span>Balance, Credit<span class="op">$</span>Limit)
<span class="kw">cor</span>(Credit<span class="op">$</span>Balance, Credit<span class="op">$</span>Income)</code></pre></div>
<p>Or we can simultaneously compute them by returning a <em>correlation matrix</em> in Table <a href="2-multiple-regression.html#tab:model3-correlation">2.2</a>. We can read off the correlation coefficient for any pair of variables by looking them up in the appropriate row/column combination.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(Credit)</code></pre></div>
<table>
<caption><span id="tab:model3-correlation">Table 2.2: </span>Correlations between credit card balance, credit limit, and credit rating</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Balance</th>
<th align="right">Limit</th>
<th align="right">Income</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Balance</td>
<td align="right">1.000</td>
<td align="right">0.862</td>
<td align="right">0.464</td>
</tr>
<tr class="even">
<td>Limit</td>
<td align="right">0.862</td>
<td align="right">1.000</td>
<td align="right">0.792</td>
</tr>
<tr class="odd">
<td>Income</td>
<td align="right">0.464</td>
<td align="right">0.792</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<p>For example, the correlation coefficient of:</p>
<ol style="list-style-type: decimal">
<li><code>Balance</code> with itself is 1</li>
<li><code>Balance</code> with <code>Limit</code> is 0.862, indicating a strong positive linear relationship, which makes sense as only individuals with large credit limits can accrue large credit card balances.</li>
<li><code>Balance</code> with <code>Income</code> is 0.464, suggestive of another positive linear relationship, although not as strong as the relationship between <code>Balance</code> and <code>Limit</code>.</li>
<li>As an added bonus, we can read off the correlation coefficient of the two explanatory variables, <code>Limit</code> and <code>Income</code> of 0.792. In this case, we say there is a high degree of <em>collinearity</em> between these two explanatory variables.</li>
</ol>
<p>Collinearity (or multicollinearity) is a phenomenon in which one explanatory variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy. So in this case, if we knew someone’s credit card <code>Limit</code> and since <code>Limit</code> and <code>Income</code> are highly correlated, we could make a fairly accurate guess as to that person’s <code>Income</code>. Or put loosely, these two variables provided redundant information. For now let’s ignore any issues related to collinearity and press on.</p>
<p>Let’s visualize the relationship of the outcome variable with each of the two explanatory variables in two separate plots:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Credit, <span class="kw">aes</span>(<span class="dt">x =</span> Limit, <span class="dt">y =</span> Balance)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Credit limit (in $)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Credit card balance (in $)&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Relationship between balance and credit limit&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)
  
<span class="kw">ggplot</span>(Credit, <span class="kw">aes</span>(<span class="dt">x =</span> Income, <span class="dt">y =</span> Balance)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Income (in $1000)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Credit card balance (in $)&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Relationship between balance and income&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:2numxplot1"></span>
<img src="ismaykim_files/figure-html/2numxplot1-1.png" alt="Relationship between credit card balance and credit limit/income" width="\textwidth" />
<p class="caption">
Figure 2.1: Relationship between credit card balance and credit limit/income
</p>
</div>
<p>First, there is a positive relationship between credit limit and balance, since as credit limit increases so also does credit card balance; this is to be expected given the strongly positive correlation coefficient of 0.862. In the case of income, the positive relationship doesn’t appear as strong, given the weakly positive correlation coefficient of 0.464. However the two plots in Figure <a href="2-multiple-regression.html#fig:2numxplot1">2.1</a> only focus on the relationship of the outcome variable with each of the explanatory variables independently. To get a sense of the <em>joint</em> relationship of all three variables simultaneously through a visualization, let’s display the data in a 3-dimensional (3D) scatterplot, where</p>
<ol style="list-style-type: decimal">
<li>The numerical outcome variable <span class="math inline">\(y\)</span> <code>Balance</code> is on the z-axis (vertical axis)</li>
<li>The two numerical explanatory variables form the x and y axes (on the floor). In this case
<ol style="list-style-type: decimal">
<li>The first numerical explanatory variable <span class="math inline">\(x_1\)</span> <code>Income</code> is on the x-axis</li>
<li>The second numerical explanatory variable <span class="math inline">\(x_2\)</span> <code>Limit</code> is on the y-axis</li>
</ol></li>
</ol>
<p>Click on the following image to open an interactive 3D scatterplot in your browser:</p>
<center>
<a target="_blank" href="http://rpubs.com/moderndive/credit_card_balance_3D_scatterplot"><img src="images/credit_card_balance_3D_scatterplot.png" title="3D scatterplot" width="600"/></a>
</center>
<p>Previously in Figure <a href="#fig:numxplot4"><strong>??</strong></a>, we plotted a “best-fitting” regression line through a set of points where the numerical outcome variable <span class="math inline">\(y\)</span> was teaching <code>score</code> and a single numerical explanatory variable <span class="math inline">\(x\)</span> <code>bty_avg</code>. What is the analogous concept when we have <em>two</em> numerical predictor variables? Instead of a best-fitting line, we now have a best-fitting <em>plane</em>, which is 3D generalization of lines which exist in 2D. Click on the following image to open an interactive plot of the regression plane in your browser.</p>
<center>
<a target="_blank" href="https://beta.rstudioconnect.com/connect/#/apps/3214/"><img src="images/credit_card_balance_regression_plane.png" title="Regression plane" width="600"/></a>
</center>
</div>
<div id="model3table" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Multiple regression</h3>
<p>Just as we did when we had a single numerical explanatory variable <span class="math inline">\(x\)</span> in Section <a href="#model1table"><strong>??</strong></a> and when we had a single categorical explanatory variable <span class="math inline">\(x\)</span> in Section <a href="#model2table"><strong>??</strong></a>, we fit a regression model and get the regression table in our two numerical explanatory variable scenario. To fit a regression model and get a table using <code>get_regression_table()</code>, we now use a <code>+</code> to consider multiple explanatory variables. In this case since we want to preform a regression of <code>Limit</code> and <code>Income</code> simultaneously, we input <code>Balance ~ Limit + Income</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Balance_model &lt;-<span class="st"> </span><span class="kw">lm</span>(Balance <span class="op">~</span><span class="st"> </span>Limit <span class="op">+</span><span class="st"> </span>Income, <span class="dt">data =</span> Credit)
<span class="kw">get_regression_table</span>(Balance_model)</code></pre></div>
<table>
<caption><span id="tab:model3-table-output">Table 2.3: </span>Multiple regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">conf_low</th>
<th align="right">conf_high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">-385.179</td>
<td align="right">19.465</td>
<td align="right">-19.8</td>
<td align="right">0</td>
<td align="right">-423.446</td>
<td align="right">-346.912</td>
</tr>
<tr class="even">
<td align="left">Limit</td>
<td align="right">0.264</td>
<td align="right">0.006</td>
<td align="right">45.0</td>
<td align="right">0</td>
<td align="right">0.253</td>
<td align="right">0.276</td>
</tr>
<tr class="odd">
<td align="left">Income</td>
<td align="right">-7.663</td>
<td align="right">0.385</td>
<td align="right">-19.9</td>
<td align="right">0</td>
<td align="right">-8.420</td>
<td align="right">-6.906</td>
</tr>
</tbody>
</table>
<p>How do we interpret these three values that define the regression plane?</p>
<ul>
<li>Intercept: -$385.18. The intercept in our case represents the credit card balance for an individual who has both a credit <code>Limit</code> of $0 and <code>Income</code> of $0. In our data however, the intercept has limited practical interpretation as no individuals had <code>Limit</code> or <code>Income</code> values of $0 and furthermore the smallest credit card balance was $0. Rather, it is used to situate the regression plane in 3D space.</li>
<li>Limit: $0.26. Now that we have multiple variables to consider, we have to add a caveat to our interpretation: <em>all other things being equal, for every increase of one unit in credit <code>Limit</code> (dollars), there is an associated increase of on average $0.26 in credit card balance</em>. Note:
<ul>
<li>Just as we did in Section <a href="#model1table"><strong>??</strong></a>, we are not making any causal statements, only statements relating to the association between credit limit and balance</li>
<li>The <em>all other things being equal</em> is making a statement about all other explanatory variables, in this case only one: <code>Income</code>. This is equivalent to saying “holding <code>Income</code> constant, we observed an associated increase of $0.26 in credit card balance for every dollar increase in credit limit”</li>
</ul></li>
<li>Income: -$7.66. Similarly, <em>all other things being equal, for every increase of one unit in <code>Income</code> (in other words, $1000 in income), there is an associated decrease of on average $7.66 in credit card balance</em>.</li>
</ul>
<p>However, recall in Figure <a href="2-multiple-regression.html#fig:2numxplot1">2.1</a> that when considered separately, both <code>Limit</code> and <code>Income</code> had positive relationships with the outcome variable <code>Balance</code>: as card holders’ credit limits increased their credit card balances tended to increase as well, and a similar relationship held for incomes and balances. In the above multiple regression, however, the slope for <code>Income</code> is now -7.66, suggesting a <em>negative relationship</em> between income and credit card balance. What explains these contradictory results? This is a phenomenon known as Simpson’s Paradox, a phenomenon in which a trend appears in several different groups of data but disappears or reverses when these groups are combined; we expand on this in Section <a href="2-multiple-regression.html#simpsonsparadox">2.3.2</a> where we’ll look at the relationship between credit <code>Limit</code> and credit card balance but split by different income bracket groups.</p>
</div>
<div id="model3points" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Observed/fitted values and residuals</h3>
<p>As we did previously, in Table <a href="2-multiple-regression.html#tab:model3-points-table">2.4</a> let’s unpack the output of the <code>get_regression_points()</code> function for our model for credit card balance for all 400 card holders in the dataset. Recall that each card holder corresponds to one of the 400 rows in the <code>Credit</code> data frame and also for one of the 400 points in the 3D scatterplots in Section <a href="2-multiple-regression.html#model3EDA">2.1.1</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span><span class="kw">get_regression_points</span>(Balance_model)
regression_points</code></pre></div>
<table>
<caption><span id="tab:model3-points-table">Table 2.4: </span>Regression points (first 5 rows of 400)</caption>
<thead>
<tr class="header">
<th align="right">ID</th>
<th align="right">Balance</th>
<th align="right">Limit</th>
<th align="right">Income</th>
<th align="right">Balance_hat</th>
<th align="right">residual</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">333</td>
<td align="right">3606</td>
<td align="right">14.9</td>
<td align="right">454</td>
<td align="right">-120.8</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">903</td>
<td align="right">6645</td>
<td align="right">106.0</td>
<td align="right">559</td>
<td align="right">344.3</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">580</td>
<td align="right">7075</td>
<td align="right">104.6</td>
<td align="right">683</td>
<td align="right">-103.4</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">964</td>
<td align="right">9504</td>
<td align="right">148.9</td>
<td align="right">986</td>
<td align="right">-21.7</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">331</td>
<td align="right">4897</td>
<td align="right">55.9</td>
<td align="right">481</td>
<td align="right">-150.0</td>
</tr>
</tbody>
</table>
<p>Recall the format of the output:</p>
<ul>
<li><code>balance</code> corresponds to <span class="math inline">\(y\)</span> the observed value</li>
<li><code>balance_hat</code> corresponds to <span class="math inline">\(\widehat{y}\)</span> the fitted value</li>
<li><code>residual</code> corresponds to the residual <span class="math inline">\(y - \widehat{y}\)</span></li>
</ul>
</div>
<div id="model3residuals" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Residual analysis</h3>
<p>Recall in Section <a href="#model1residuals"><strong>??</strong></a>, our first residual analysis plot investigated the presence of any systematic pattern in the residuals when we had a single numerical predictor: <code>bty_age</code>. For the <code>Credit</code> card dataset, since we have two numerical predictors, <code>Limit</code> and <code>Income</code>, we must perform this twice:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> Limit, <span class="dt">y =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Credit limit (in $)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Residual&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Residuals vs credit limit&quot;</span>)
  
<span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> Income, <span class="dt">y =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Income (in $1000)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Residual&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Residuals vs income&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-18"></span>
<img src="ismaykim_files/figure-html/unnamed-chunk-18-1.png" alt="Residuals vs credit limit and income" width="\textwidth" />
<p class="caption">
Figure 2.2: Residuals vs credit limit and income
</p>
</div>
<p>In this case, there does appear to be a systematic pattern to the residuals, as the scatter of the residuals around the line <span class="math inline">\(y=0\)</span> is definitely not consistent. This behavior of the residuals is further evidenced by the histogram of residuals in Figure @ref(fig:model3_residuals_hist). We observe that the residuals have a slight right-skew (recall we say that data is right-skewed, or positively-skewed, if there is a tail to the right). Ideally, these residuals should be bell-shaped around a residual value of 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Residual&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/model3_residuals_hist-1.png" alt="Plot of residuals over continent" width="\textwidth" />
<p class="caption">
(#fig:model3_residuals_hist)Plot of residuals over continent
</p>
</div>
<p>Another way to interpret this histogram is that since the residual is computed as <span class="math inline">\(y - \widehat{y}\)</span> = <code>balance</code> - <code>balance_hat</code>, we have some values where the fitted value <span class="math inline">\(\widehat{y}\)</span> is very much lower than the observed value <span class="math inline">\(y\)</span>. In other words, we are underestimating certain credit card holder’s balance by a very large amount.</p>
</div>
<div id="your-turn" class="section level3">
<h3><span class="header-section-number">2.1.5</span> Your turn</h3>
<p>Repeat this same analysis but using <code>Age</code> and <code>Rating</code> as the two numerical explanatory variables. Recall the four steps we’ve been following:</p>
<ol style="list-style-type: decimal">
<li>Perform an exploratory data analysis (EDA)</li>
<li>Fit a linear regression model and get information about the model</li>
<li>Get information on all <span class="math inline">\(n\)</span> data points considered in this analysis.</li>
<li>Perform a residual analysis and look for any systematic patterns in the residuals.</li>
</ol>
</div>
</div>
<div id="model4" class="section level2">
<h2><span class="header-section-number">2.2</span> One numerical &amp; one categorical explanatory variable</h2>
<p>Let’s revisit the instructor evaluation data introduced in Section <a href="#model1"><strong>??</strong></a>, where we studied the relationship between instructor evaluation scores and their beauty scores. This analysis suggested that there is a positive relationship between <code>bty_avg</code> and <code>score</code>, in other words as instructors had higher beauty scores, they also tended to have higher teaching evaluation scores. Now let’s say instead of <code>bty_avg</code> we are interested in the numerical explanatory variable <span class="math inline">\(x_1\)</span> <code>age</code> and furthermore we want to use a second explanatory variable <span class="math inline">\(x_2\)</span>, the (binary) categorical variable <code>gender</code>. Our modeling scenario now becomes</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>. As before, instructor evaluation score.</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>A numerical explanatory variable <span class="math inline">\(x_1\)</span>: In this case, their age.</li>
<li>A categorical explanatory variable <span class="math inline">\(x_2\)</span>: In this case, their binary gender.</li>
</ol></li>
</ol>
<div id="model4EDA" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Exploratory data analysis</h3>
<p>Let’s reload the <code>evals</code> data and <code>select()</code> only the needed subset of variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="kw">url</span>(<span class="st">&quot;http://www.openintro.org/stat/data/evals.RData&quot;</span>))
evals &lt;-<span class="st"> </span>evals <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(score, age, gender)</code></pre></div>
<p>Let’s look at the raw data values both by bringing up RStudio’s spreadsheet viewer and the <code>glimpse()</code> function, although in Table <a href="2-multiple-regression.html#tab:model4-data-preview">2.5</a> we only show 5 randomly selected instructors out of 463:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(evals)</code></pre></div>
<table>
<caption><span id="tab:model4-data-preview">Table 2.5: </span>Random sample of 5 instructors</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">score</th>
<th align="right">bty_avg</th>
<th align="right">age</th>
<th align="left">gender</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>290</td>
<td align="right">3.6</td>
<td align="right">6.67</td>
<td align="right">34</td>
<td align="left">male</td>
</tr>
<tr class="even">
<td>341</td>
<td align="right">4.9</td>
<td align="right">3.50</td>
<td align="right">43</td>
<td align="left">male</td>
</tr>
<tr class="odd">
<td>199</td>
<td align="right">3.3</td>
<td align="right">2.33</td>
<td align="right">47</td>
<td align="left">male</td>
</tr>
<tr class="even">
<td>47</td>
<td align="right">4.4</td>
<td align="right">4.67</td>
<td align="right">33</td>
<td align="left">female</td>
</tr>
<tr class="odd">
<td>215</td>
<td align="right">4.7</td>
<td align="right">3.67</td>
<td align="right">60</td>
<td align="left">male</td>
</tr>
</tbody>
</table>
<p>Let’s look at some summary statistics:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(evals)</code></pre></div>
<pre><code>     score         bty_avg          age          gender   
 Min.   :2.30   Min.   :1.67   Min.   :29.0   female:195  
 1st Qu.:3.80   1st Qu.:3.17   1st Qu.:42.0   male  :268  
 Median :4.30   Median :4.33   Median :48.0               
 Mean   :4.17   Mean   :4.42   Mean   :48.4               
 3rd Qu.:4.60   3rd Qu.:5.50   3rd Qu.:57.0               
 Max.   :5.00   Max.   :8.17   Max.   :73.0               </code></pre>
<p>In Figure <a href="2-multiple-regression.html#fig:numxcatxplot1">2.3</a>, we plot a scatterplot of <code>score</code> over <code>age</code>, but given that <code>gender</code> is a binary categorical variable</p>
<ol style="list-style-type: decimal">
<li>We can assign a color to points from each of the two levels of <code>gender</code>: female and male</li>
<li>Furthermore, the <code>geom_smooth(method = &quot;lm&quot;, se = FALSE)</code> layer automatically fits a different regression line for each</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(evals, <span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> score, <span class="dt">col =</span> gender)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;Gender&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:numxcatxplot1"></span>
<img src="ismaykim_files/figure-html/numxcatxplot1-1.png" alt="Instructor evaluation scores at UT Austin split by gender (jittered)" width="\textwidth" />
<p class="caption">
Figure 2.3: Instructor evaluation scores at UT Austin split by gender (jittered)
</p>
</div>
<p>We notice some interesting trends:</p>
<ol style="list-style-type: decimal">
<li>There are almost no women faculty over the age of 60.</li>
<li>Fitting separate regression lines for men and women, we see they have different slopes. We see that the associated effect of increasing age seems to be much harsher for women than men. In other words, as women age, the drop in their teaching score appears to be more faster.</li>
</ol>
</div>
<div id="model4table" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Multiple regression</h3>
<p>Much like we started to consider multiple explanatory variables using the <code>+</code> sign in Section(model3table), let’s fit a regression model and get the regression table, this time saving our regression model fit in <code>score_model_2</code> so as to not overwrite the model <code>score_model</code> from Section <a href="#model1table"><strong>??</strong></a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">score_model_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>gender, <span class="dt">data =</span> evals)
<span class="kw">get_regression_table</span>(score_model_<span class="dv">2</span>)</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-24">Table 2.6: </span>Regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">conf_low</th>
<th align="right">conf_high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">4.484</td>
<td align="right">0.125</td>
<td align="right">35.79</td>
<td align="right">0.000</td>
<td align="right">4.238</td>
<td align="right">4.730</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="right">-0.009</td>
<td align="right">0.003</td>
<td align="right">-3.28</td>
<td align="right">0.001</td>
<td align="right">-0.014</td>
<td align="right">-0.003</td>
</tr>
<tr class="odd">
<td align="left">gendermale</td>
<td align="right">0.191</td>
<td align="right">0.052</td>
<td align="right">3.63</td>
<td align="right">0.000</td>
<td align="right">0.087</td>
<td align="right">0.294</td>
</tr>
</tbody>
</table>
<p>The modeling equation for this scenario is:</p>
<p><span class="math display">\[
\begin{align}
\widehat{y} &amp;= b_0 + b_1 * x_1 + b_2 * x_2 \\
\widehat{\mbox{score}} &amp;= b_0 + b_{\mbox{age}} * \mbox{age} + b_{\mbox{male}} * \mathbb{1}[\mbox{is male}] \\
\end{align}
\]</span> where <span class="math inline">\(\mathbb{1}[\mbox{is male}]\)</span> is an <em>indicator function</em> for <code>sex == male</code>. In other words, <span class="math inline">\(\mathbb{1}[\mbox{is male}]\)</span> equals one if the current observation corresponds to a male professor, and 0 if the current observation corresponds to a femal professor. This model can be visualized in Figure <a href="2-multiple-regression.html#fig:numxcatxplot2">2.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:numxcatxplot2"></span>
<img src="ismaykim_files/figure-html/numxcatxplot2-1.png" alt="Instructor evaluation scores at UT Austin by gender: same slope" width="\textwidth" />
<p class="caption">
Figure 2.4: Instructor evaluation scores at UT Austin by gender: same slope
</p>
</div>
<p>We see that:</p>
<ul>
<li>Females are treated as the baseline for comparison for no other reason than “female” is alphabetically earlier than “male”. The <span class="math inline">\(b_{male} = 0.1906\)</span> is the vertical “bump” that men get in their teaching evaluation scores. Or more precisely, it is the average difference in teaching score that men get <em>relative to the baseline of women</em></li>
<li>Accordingly, the intercepts are (which in this case make no sense since no instructor can have age 0):
<ul>
<li>for women: <span class="math inline">\(b_0\)</span> = 4.484</li>
<li>for men: <span class="math inline">\(b_0 + b_{male}\)</span> = 4.484 + 0.191 = 4.675</li>
</ul></li>
<li>Both men and women have the same slope. In other words, <em>in this model</em> the associated effect of age is the same for men and women: all other things being equal, for every increase in 1 in age, there is on average an associated decrease of <span class="math inline">\(b_{age}\)</span> = -0.0086 in teaching score</li>
</ul>
<p>But wait, why is Figure <a href="2-multiple-regression.html#fig:numxcatxplot2">2.4</a> is different than Figure <a href="2-multiple-regression.html#fig:numxcatxplot1">2.3</a>! What is going on? What we have in the original plot is we’ve incorporated what’s know as an <em>interaction effect</em> between age and gender.</p>
</div>
<div id="model4interactiontable" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Mutiple regression with interaction effects</h3>
<p>We say a model has an <em>interaction effect</em> if the associated effect of one variable <em>depends on the value of another variable</em>. In this case, the effect of <code>age</code> will depend on the value of <code>gender</code>. Put differently, the effect of age on teaching scores will differ for men and for women, as was suggested by the different slopes for men and women in our visual exploratory data analysis in Figure <a href="2-multiple-regression.html#fig:numxcatxplot1">2.3</a>.</p>
<p>Let’s fit a regression with an interaction term. Instead of using the <code>+</code> sign in the enumeration of explanatory variables, we use the <code>*</code> sign. Let’s fit this regression and save it in <code>score_model_3</code>, then we get the regression table using the <code>get_regression_table()</code> function as before.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">score_model_interaction &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>age <span class="op">*</span><span class="st"> </span>gender, <span class="dt">data =</span> evals)
<span class="kw">get_regression_table</span>(score_model_interaction)</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-26">Table 2.7: </span>Regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">conf_low</th>
<th align="right">conf_high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">4.883</td>
<td align="right">0.205</td>
<td align="right">23.80</td>
<td align="right">0.000</td>
<td align="right">4.480</td>
<td align="right">5.286</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="right">-0.018</td>
<td align="right">0.004</td>
<td align="right">-3.92</td>
<td align="right">0.000</td>
<td align="right">-0.026</td>
<td align="right">-0.009</td>
</tr>
<tr class="odd">
<td align="left">gendermale</td>
<td align="right">-0.446</td>
<td align="right">0.265</td>
<td align="right">-1.68</td>
<td align="right">0.094</td>
<td align="right">-0.968</td>
<td align="right">0.076</td>
</tr>
<tr class="even">
<td align="left">age:gendermale</td>
<td align="right">0.014</td>
<td align="right">0.006</td>
<td align="right">2.45</td>
<td align="right">0.015</td>
<td align="right">0.003</td>
<td align="right">0.024</td>
</tr>
</tbody>
</table>
<p>The modeling equation for this scenario is:</p>
<p><span class="math display">\[
\begin{align}
\widehat{y} &amp;= b_0 + b_1*x_1 + b_2*x_2 + b_3*x_1*x_2\\
\widehat{\mbox{score}} &amp;= b_0 + b_{\mbox{age}}*\mbox{age} + b_{\mbox{male}}*\mathbb{1}[\mbox{is male}] + b_{\mbox{age,male}}*\mbox{age}*\mathbb{1}[\mbox{is male}] \\
\end{align}
\]</span></p>
<p>Oof, that’s a lot of rows in the regression table output and a lot of terms in the model equation. The fourth term being added on the right hand side of the equation corresponds to the <em>interaction term</em>. Let’s simply things by considering men and women separately. First, recall that <span class="math inline">\(\mathbb{1}[\mbox{is male}]\)</span> equals 1 if a particular observation (or row in <code>evals</code>) corresponds to a male instructors. In this case, using the values from the regression table the fitted value of <span class="math inline">\(\widehat{\mbox{score}}\)</span> is:</p>
<p><span class="math display">\[
\begin{align}
\widehat{\mbox{score}} &amp;= b_0 + b_{\mbox{age}}*\mbox{age} + b_{\mbox{male}}*\mathbb{1}[\mbox{is male}] + b_{\mbox{age,male}}*\mbox{age}*\mathbb{1}[\mbox{is male}] \\
&amp;= b_0 + b_{\mbox{age}}*\mbox{age} + b_{\mbox{male}}*1 + b_{\mbox{age,male}}\mbox{age}*1 \\
&amp;= \left(b_0 + b_{\mbox{male}}\right) + \left(b_{\mbox{age}} +  b_{\mbox{age,male}} \right)*\mbox{age} \\
&amp;= \left(4.883 + -0.446\right) + \left(-0.018 +  0.014 \right)*\mbox{age} \\
&amp;= 4.437 -0.004*\mbox{age}
\end{align}
\]</span></p>
<p>Second, recall that <span class="math inline">\(\mathbb{1}[\mbox{is male}]\)</span> equals 0 if a particular observation corresponds to a female instructors. Again, using the values from the regression table the fitted value of <span class="math inline">\(\widehat{\mbox{score}}\)</span> is:</p>
<p><span class="math display">\[
\begin{align}
\widehat{\mbox{score}} &amp;= b_0 + b_{\mbox{age}}*\mbox{age} + b_{\mbox{male}}*\mathbb{1}[\mbox{is male}] + b_{\mbox{age,male}}*\mbox{age}*\mathbb{1}[\mbox{is male}] \\
&amp;= b_0 + b_{\mbox{age}}*\mbox{age} + b_{\mbox{male}}*0 + b_{\mbox{age,male}}\mbox{age}*0 \\
&amp;= b_0 + b_{\mbox{age}}*\mbox{age}\\
&amp;= 4.883 -0.018*\mbox{age}
\end{align}
\]</span></p>
<p>Let’s summarize these values in a table:</p>
<table>
<caption><span id="tab:unnamed-chunk-27">Table 2.8: </span>Comparison of male and female intercepts and age slopes</caption>
<thead>
<tr class="header">
<th align="left">Gender</th>
<th align="right">Intercept</th>
<th align="right">Slope for age</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Male instructors</td>
<td align="right">4.44</td>
<td align="right">-0.004</td>
</tr>
<tr class="even">
<td align="left">Female instructors</td>
<td align="right">4.88</td>
<td align="right">-0.018</td>
</tr>
</tbody>
</table>
<p>We see that while male instructors have a lower intercept, as they age, they have a less steep associated average decrease in teaching scores: 0.004 units teaching score units per year as opposed to -0.018 for women. This is consistent with the different slopes and intercepts of the red and blue regression lines fit in Figure <a href="2-multiple-regression.html#fig:numxcatxplot1">2.3</a>. Recall our definition of a model having an interaction effect: when the associated effect of one variable, in this case age, depends on the value of another variable, in this case gender.</p>
<p>But how do we know when it’s appropriate to include an interaction effect? For example, which is the more appropriate model? The regular multiple regression model without an interaction term we saw in Section @ref{model4table} or the multiple regression model with the interaction term we just saw? We’ll revisit this question in Section <a href="#inference-for-regression"><strong>??</strong></a>.</p>
</div>
<div id="model4points" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Observed/fitted values and residuals</h3>
<p>Now say we want to apply the above calculations for male and female instructors for all 463 instructors in the <code>evals</code> dataset. As our multiple regression models get more and more complex, computing such values by hand gets more and more tedious. The <code>get_regression_points()</code> function spares us this tedium and returns all fitted values and all residuals. For simplicity, let’s focus only on the fitted interaction model, which is saved in <code>score_model_interaction</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span><span class="kw">get_regression_points</span>(score_model_interaction)
regression_points</code></pre></div>
<table>
<caption><span id="tab:model4-points-table">Table 2.9: </span>Regression points (first 5 rows of 463)</caption>
<thead>
<tr class="header">
<th align="right">ID</th>
<th align="right">score</th>
<th align="right">age</th>
<th align="left">gender</th>
<th align="right">score_hat</th>
<th align="right">residual</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">4.7</td>
<td align="right">36</td>
<td align="left">female</td>
<td align="right">4.25</td>
<td align="right">0.448</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">4.1</td>
<td align="right">36</td>
<td align="left">female</td>
<td align="right">4.25</td>
<td align="right">-0.152</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">3.9</td>
<td align="right">36</td>
<td align="left">female</td>
<td align="right">4.25</td>
<td align="right">-0.352</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">4.8</td>
<td align="right">36</td>
<td align="left">female</td>
<td align="right">4.25</td>
<td align="right">0.548</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">4.6</td>
<td align="right">59</td>
<td align="left">male</td>
<td align="right">4.20</td>
<td align="right">0.399</td>
</tr>
</tbody>
</table>
<p>Recall the format of the output:</p>
<ul>
<li><code>score</code> corresponds to <span class="math inline">\(y\)</span> the observed value</li>
<li><code>score_hat</code> corresponds to <span class="math inline">\(\widehat{y} = \widehat{\mbox{score}}\)</span> the fitted value</li>
<li><code>residual</code> corresponds to the residual <span class="math inline">\(y - \widehat{y}\)</span></li>
</ul>
</div>
<div id="model4residuals" class="section level3">
<h3><span class="header-section-number">2.2.5</span> Residual analysis</h3>
<!--
## Two categorical $x$ {#model5}

Let's look at the `biopics` dataset in the
[`fivethirtyeight`](https://rudeboybert.github.io/fivethirtyeight/) package.
After loading the package, run `?biopics` in the console to read the help file.
This data is from the article ["Straight Outta Compton" Is The Rare Biopic Not About White Dudes](https://fivethirtyeight.com/features/straight-outta-compton-is-the-rare-biopic-not-about-white-dudes/).  

First let's load the data and look at a random sample of 5 rows:


```r
library(fivethirtyeight)
biopics <- biopics %>%
  select(title, box_office, person_of_color, subject_sex) %>%
  # Remove those that are missing
  filter(!is.na(box_office))
```


title             box_office  person_of_color   subject_sex 
---------------  -----------  ----------------  ------------
Prefontaine           532000  FALSE             Male        
Swoon                 340000  FALSE             Male        
Jersey Boys         47000000  FALSE             Male        
Blaze               19100000  FALSE             Male        
La Vie en Rose      10300000  FALSE             Female      




Before we conduct an exploratory data analysis (EDA) of the `biopics` data, let's first
have a discussion $\log$-transformations.

### log-transformations

Let's consider a histogram of the box office revenues for the `biopics` dataset


```r
ggplot(biopics, aes(x = box_office)) +
  geom_histogram(color = "white") +
  labs(x = "Box office revenue")
```

<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/logtransform1-1.png" alt="Histogram of box office revenue" width="\textwidth" />
<p class="caption">(\#fig:logtransform1)Histogram of box office revenue</p>
</div>

In Figure \@ref(fig:logtransform1), we see there is a right-skew to both the
x-values. This is because there are a few Hollywood blockbusters being compared
with many (likely) smaller-scale independent films. Let's look at the top 5 and
bottom 5 grossing movies in this dataset: 


Table: (\#tab:unnamed-chunk-31)Top 5 grossing movies in data

title                  box_office  person_of_color   subject_sex 
--------------------  -----------  ----------------  ------------
American Sniper         350000000  FALSE             Male        
The Blind Side          256000000  TRUE              Male        
Lincoln                 182000000  FALSE             Male        
A Beautiful Mind        171000000  FALSE             Male        
Catch Me If You Can     164000000  FALSE             Male        


Table: (\#tab:unnamed-chunk-32)Bottom 5 grossing movies in data

title                    box_office  person_of_color   subject_sex 
----------------------  -----------  ----------------  ------------
Caravaggio                     3150  FALSE             Male        
Set Fire to the Stars          3270  FALSE             Male        
My Dinner with Andre           5070  FALSE             Male        
My Dinner with Andre           5070  FALSE             Male        
Kid Cannabis                   5570  FALSE             Male        

The scale of box office revenue is completely different! Hence, in Figure \@ref(fig:logtransform1), it's really hard to see what's going on at the
lower-end. 

Let's unskew this variable and compare not *absolute* differences, but rather,
*relative* differences i.e. differences in "order of magnitude" using a
`log10()` transformation:


```r
ggplot(biopics, aes(x = log10(box_office))) +
  geom_histogram(color = "white") +
  labs(x = "log10(Box office revenue)")
```

<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/logtransform2-1.png" alt="Histogram of log10(box office revenue)" width="\textwidth" />
<p class="caption">(\#fig:logtransform2)Histogram of log10(box office revenue)</p>
</div>

We can see a little better what's going on at the lower end of the box office revenue scale.
However the values on the axes require a little thinking to process. For example
at $x=7$, this corresponds to movies with revenue of $10^7 = 10,000,000$
dollars. So instead, let's *rescale* the x-axis so that it displays the data in
their original units.


```r
ggplot(biopics, aes(x = box_office)) +
  geom_histogram(color = "white") +
  scale_x_log10() +
  labs(x = "Box office revenue (log10-scale))")
```

<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/logtransform3-1.png" alt="Histogram of box office revenue (log-10 scale)" width="\textwidth" />
<p class="caption">(\#fig:logtransform3)Histogram of box office revenue (log-10 scale)</p>
</div>

Note that

* The two plots are identical, but the values on the x-axis are different.
* In both Figure \@ref(fig:logtransform2) Figure \@ref(fig:logtransform3), equivalent distances on each axes correspond to not equivalent absolute differences, but equivalent relative/multiplicative differences. So for example, the horizontal distance on the plot from Budget = `1e+05` = $10^5$ to Budget  = `1e+06` = $10^6$ is equal to the horizontal distance on the plot from Budget = `1e+06` = $10^6$ to Budget = `1e+07` = $10^7$.



### Exploratory data analysis {#model5EDA}

Let's now consider the box office gross earnings in the US of these movies on a log10
scale:


```r
ggplot(biopics, aes(x = subject_sex, y = box_office)) +
  facet_wrap(~person_of_color, nrow = 1) +
  scale_y_log10() +
  geom_boxplot() +
  labs(x = "Subject sex", y = "Box office revenue (log10-scale)", title =
  "Person of color?")
```

<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/2catxplot-1.png" alt="Box office revenue vs biopic subject info" width="\textwidth" />
<p class="caption">(\#fig:2catxplot)Box office revenue vs biopic subject info</p>
</div>

It seems in this dataset, men of color had the highest median box office gross. Let's
look at a table of means instead of medians.


```r
biopics %>%
  group_by(person_of_color, subject_sex) %>%
  summarise(mean_box_office = mean(box_office)) %>%
  arrange(desc(mean_box_office))
```

Table: (\#tab:unnamed-chunk-34)Group means

person_of_color   subject_sex    mean_box_office
----------------  ------------  ----------------
TRUE              Male                  31648028
FALSE             Male                  22871074
TRUE              Female                20035820
FALSE             Female                18088799

Keep in mind two things though. First, the sample sizes are different:


```r
biopics %>%
  group_by(person_of_color, subject_sex) %>%
  summarise(n = n()) %>%
  arrange(desc(n))
```

Table: (\#tab:unnamed-chunk-36)Number of movies of each type in dataset

person_of_color   subject_sex      n
----------------  ------------  ----
FALSE             Male           268
FALSE             Female          93
TRUE              Male            61
TRUE              Female          15

Second, can we *generalize* these results to *all movies*? How was the selection
of movies sampled? Is it a representative sample of all movies, or was their a
systematic reason these were included?



### Multiple regression {#model5table}


Let's now compute the *regression table*. Let's jump straight into considering
a model that incorporates an interaction term as described earlier. 


```r
box_office_model <- lm(box_office ~ person_of_color * subject_sex, data = biopics)
get_regression_table(box_office_model)
```

Table: (\#tab:unnamed-chunk-38)Regression table

term                                   estimate   std_error   statistic   p_value    conf_low   conf_high
------------------------------------  ---------  ----------  ----------  --------  ----------  ----------
intercept                              18088799     3964762       4.562     0.000    10296227    25881371
person_of_colorTRUE                     1947021    10638573       0.183     0.855   -18962645    22856687
subject_sexMale                         4782275     4601541       1.039     0.299    -4261860    13826410
person_of_colorTRUE:subject_sexMale     6829933    11941509       0.572     0.568   -16640597    30300464

The model formula is

$$
\begin{align}
\widehat{y} &= b_0 + b_1 x_1 + b_2 x_2 + b_3 x_1x_2\\
\widehat{score} &= b_0 + b_{color}\mathbb{1}[\mbox{of color}] + b_{male} \mathbb{1}[\mbox{is male}] + b_{color,male}\mathbb{1}[\mbox{of color}]\mathbb{1}[\mbox{is male}] \\
\end{align}
$$


Recreate four group means from the Table 6.15 above:

* Female not of color: 18088799 = 18088799 = $b_0$. Note: *Women not of color are the baseline group*.
* Male not of color: 22871074 = 18088799 + 4782275 = $b_0 + b_{male}$
* Female of color: 20035820 = 18088799 + 1947021 = $b_0 + b_{color}$
* Male of color: 31648028 = 18088799 + 1947021 + 4782275 + 6829933 = $b_0 + b_{color} + b_{male} + b_{color,male}$. Note: $b_{color,male}$ is the *interaction term*.






### Observed/fitted values and residuals {#model5points}
### Residual analysis {#model5residuals}

-->
</div>
</div>
<div id="related-topics" class="section level2">
<h2><span class="header-section-number">2.3</span> Related topics</h2>
<div id="correlationcoefficient2" class="section level3">
<h3><span class="header-section-number">2.3.1</span> More on the correlation coefficient</h3>
<p>Recall in Table <a href="2-multiple-regression.html#tab:model3-correlation">2.2</a>, we saw that the correlation coefficient between <code>Income</code> in thousands of dollars and credit card <code>Balance</code> was 0.862. What if in instead we looked the correlation coefficient between <code>Income</code> and credit card <code>Balance</code>, but where <code>Income</code> was in dollars and not thousands of dollars? i.e. we multiplied <code>Income</code> by 1000?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
<span class="kw">data</span>(Credit)
Credit <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(Balance, Limit, Income) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Income =</span> Income <span class="op">*</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cor</span>()</code></pre></div>
<table>
<caption><span id="tab:cor-credit-2">Table 2.10: </span>Correlation between income (in $) and credit card balance</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Balance</th>
<th align="right">Limit</th>
<th align="right">Income</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Balance</td>
<td align="right">1.000</td>
<td align="right">0.862</td>
<td align="right">0.464</td>
</tr>
<tr class="even">
<td>Limit</td>
<td align="right">0.862</td>
<td align="right">1.000</td>
<td align="right">0.792</td>
</tr>
<tr class="odd">
<td>Income</td>
<td align="right">0.464</td>
<td align="right">0.792</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<p>We see it is the same! We say that correlation coefficient is invariant to linear transformations! In other words</p>
<ul>
<li>The correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> will be the same as</li>
<li>The correlation between <span class="math inline">\(a\times x + b\)</span> and <span class="math inline">\(y\)</span> where <span class="math inline">\(a, b\)</span> are numerical values (real numbers in mathematical terms)</li>
</ul>
</div>
<div id="simpsonsparadox" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Simpson’s Paradox</h3>
<p>Recall in Section <a href="2-multiple-regression.html#model3">2.1</a>, we saw the two following seemingly contradictory results when studying the relationship between credit card balance, credit limit, and income. On the one hand, the right hand plot of Figure <a href="2-multiple-regression.html#fig:2numxplot1">2.1</a> suggested that credit card balance and income were positively related:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-40"></span>
<img src="ismaykim_files/figure-html/unnamed-chunk-40-1.png" alt="Relationship between credit card balance and credit limit/income" width="\textwidth" />
<p class="caption">
Figure 2.5: Relationship between credit card balance and credit limit/income
</p>
</div>
<p>On the other hand, the multiple regression in Table <a href="2-multiple-regression.html#tab:model3-table-output">2.3</a>, suggested that when modeling credit card balance as a function of both credit limit and income at the same time, credit limit has a negative relationship with balance, as evidenced by the slope of -7.66. How can this be?</p>
<p>First, let’s dive a little deeper into the explanatory variable <code>Limit</code>. Figure @ref(fig:credit_limit_quartiles) shows a histogram of all 400 values of <code>Limit</code>, along with vertical red lines that cut up the data into quartiles, meaning:</p>
<ol style="list-style-type: decimal">
<li>25% of credit limits were between $0 and $3088. Let’s call this the “low” credit limit bracket.</li>
<li>25% of credit limits were between $3088 and $4622. Let’s call this the “medium-low” credit limit bracket.</li>
<li>25% of credit limits were between $4622 and $5873. Let’s call this the “medium-high” credit limit bracket.</li>
<li>25% of credit limits were over $5873. Let’s call this the “high” credit limit bracket.</li>
</ol>
<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/credit_limit_quartiles-1.png" alt="Histogram of credit limits and quartiles" width="\textwidth" />
<p class="caption">
(#fig:credit_limit_quartiles)Histogram of credit limits and quartiles
</p>
</div>
<p>Let’s now display</p>
<ol style="list-style-type: decimal">
<li>The scatterplot showing the relationship between credit card balance and limit (the right-hand plot of Figure <a href="2-multiple-regression.html#fig:2numxplot1">2.1</a>).</li>
<li>The scatterplot showing the relationship between credit card balance and limit now with a color aesthetic added corresponding to the credit limit bracket.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:2numxplot4"></span>
<img src="ismaykim_files/figure-html/2numxplot4-1.png" alt="Relationship between credit card balance and income for different credit limit brackets" width="\textwidth" />
<p class="caption">
Figure 2.6: Relationship between credit card balance and income for different credit limit brackets
</p>
</div>
<p>The left-hand plot focuses of the relationship between balance and income in aggregate, but the right-hand plot focuses on the relationship between balance and income <em>broken down by credit limit bracket</em>. Whereas in aggregate there is an overall positive relationship, but when broken down We now see that for the</p>
<ol style="list-style-type: decimal">
<li>low</li>
<li>medium-low</li>
<li>medium-high</li>
</ol>
<p>income bracket groups, the strong positive relationship between credit card balance and income disappears! Only for the high bracket does the relationship stay somewhat positive. In this example credit limit is a <em>confounding variable</em> for credit card balance and income.</p>
<!--
Alternatively, we could also have used facets, where each facet has roughly 25% of people based
on the credit limit bracket. However, IMO the above plot is easier to read.

<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/2numxplot5-1.png" alt="Relationship between credit card balance and income for different credit limit brackets" width="\textwidth" />
<p class="caption">(\#fig:2numxplot5)Relationship between credit card balance and income for different credit limit brackets</p>
</div>
-->
</div>
<div id="script-of-r-code" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Script of R code</h3>
<p>An R script file of all R code used in this chapter is available <a href="https://moderndive.netlify.com/scripts/07-multiple-regression.R">here</a>.</p>

<div id="refs" class="references">
<div>
<p>Chihara, Laura M., and Tim C. Hesterberg. 2011. <em>Mathematical Statistics with Resampling and R</em>. Hoboken, NJ: John Wiley; Sons. <a href="https://sites.google.com/site/chiharahesterberg/home" class="uri">https://sites.google.com/site/chiharahesterberg/home</a>.</p>
</div>
<div>
<p>Diez, David M, Christopher D Barr, and Mine Çetinkaya-Rundel. 2014. <em>Introductory Statistics with Randomization and Simulation</em>. First Edition. <a href="https://www.openintro.org/stat/textbook.php?stat_book=isrs" class="uri">https://www.openintro.org/stat/textbook.php?stat_book=isrs</a>.</p>
</div>
<div>
<p>Grolemund, Garrett, and Hadley Wickham. 2016. <em>R for Data Science</em>. <a href="http://r4ds.had.co.nz/" class="uri">http://r4ds.had.co.nz/</a>.</p>
</div>
<div>
<p>Xie, Yihui. 2017. <em>Bookdown: Authoring Books and Technical Documents with R Markdown</em>. <a href="https://CRAN.R-project.org/package=bookdown" class="uri">https://CRAN.R-project.org/package=bookdown</a>.</p>
</div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ismayc/moderndiver-book/edit/master/07-multiple-regression.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
